import logging
import duckdb
import polars as pl
import shutil
import time
from pathlib import Path
from datetime import datetime
from extract_data import fetch_migrant_data

def extract_daily_data():
    """
    Extracts the latest UK Government weekly statistical data on migrant crossings

    Args:
        None
    Returns:
        None
    """

    # setup logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )

    logging.info(f"Running {extract_daily_data.__name__}")

    # setup duckdb
    con = duckdb.connect('migrant_crossings_db.duckdb')
    table_name = "raw.migrants_arrived_daily"

    # setup paths
    p = Path()
    incoming_path = p / 'incoming'

    schema_overrides = {
        'Date': pl.Date(),
        'Migrants arrived': pl.Int16(),
        'Boats arrived': pl.Int16(),
        'Boats arrived - involved in uncontrolled landings': pl.Int16(),
        'Notes': pl.String()
    }

    schema = [
        'date_ending',
        'migrants_arrived',
        'boats_arrived',
        'boats_arrived_involved_in_uncontrolled_landings',
        'notes',
        'source'
    ]

    all_data = []
    for f in incoming_path.glob('*.ods'):
        _df = pl.read_ods(
            source=f,
            schema_overrides=schema_overrides,
            sheet_name='SB_01'
        )
        _df = _df.with_columns(
            pl.lit(f.name).alias('source')
        )
        all_data.append(_df)

    # create the polars dataframe
    df = pl.concat(all_data)

    # apply the expected table schema for column names
    df.columns = schema

    # sort by date descending (latest first)
    df = df.sort(by=pl.col('date_ending'), descending=True)

    # add sdc flags for upsert and merging
    current_date = datetime.now().date()
    df = df.with_columns(
        pl.lit(True).alias('is_current'),
        pl.lit(current_date).alias('begin_date').cast(pl.Date()),
        pl.lit(None).alias('end_date').cast(pl.Date())
    )

    # register the df for ingestion into the database
    con.register('polarsDF', df)

    # upsert and merge
    try:
        logging.info("Attempting merge...")
        con.sql(f"""
        MERGE into {table_name} AS target
        USING polarsDF AS source
        ON target.date_ending = source.date_ending
        AND target.is_current = true
        WHEN MATCHED AND (
               target.migrants_arrived <> source.migrants_arrived OR
               target.boats_arrived    <> source.boats_arrived    OR
               target.boats_arrived_involved_in_uncontrolled_landings  <> source.boats_arrived_involved_in_uncontrolled_landings OR
               target.notes <> source.notes
            ) THEN UPDATE SET
            end_date    = CURRENT_DATE - INTERVAL '1 day',
            is_current  = false
        WHEN NOT MATCHED BY SOURCE AND target.is_current = true THEN UPDATE SET
            end_date    = CURRENT_DATE - INTERVAL '1 day',
            is_current  = false
        WHEN NOT MATCHED BY TARGET THEN INSERT (
            record_id,
            date_ending,
            migrants_arrived,
            boats_arrived,
            boats_arrived_involved_in_uncontrolled_landings,
            notes,
            source,
            is_current,
            begin_date,
            end_date
        ) VALUES (
            nextval('duck_record_sequence'),
            source.date_ending,
            source.migrants_arrived,
            source.boats_arrived,
            source.boats_arrived_involved_in_uncontrolled_landings,
            source.notes,
            source.source,
            source.is_current,
            source.begin_date,
            source.end_date
        )
        """)
        logging.info(f"Updated -> {table_name}")
    except Exception as e:
        con.close()
        logging.critical(f"Something went wrong -> {e}")

    con.close()
    logging.info("Connection to duckdb closed")

if __name__ == "__main__":
    extract_daily_data()